{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.workflow import Event\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "\n",
    "class RetrieverEvent(Event):\n",
    "    \"\"\"Result of running retrieval\"\"\"\n",
    "\n",
    "    nodes: list[NodeWithScore]\n",
    "\n",
    "\n",
    "class CreateCitationsEvent(Event):\n",
    "    \"\"\"Add citations to the nodes.\"\"\"\n",
    "\n",
    "    nodes: list[NodeWithScore]\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing index...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "def load_or_create_index(directory_path, persist_dir):\n",
    "        if os.path.exists(persist_dir):\n",
    "            print(\"Loading existing index...\")\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            print(\"Creating new index...\")\n",
    "            documents = SimpleDirectoryReader(directory_path, recursive=True).load_data()\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents=documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=persist_dir)\n",
    "        return index\n",
    "\n",
    "index = load_or_create_index(\n",
    "            \"data/get-started/\",\n",
    "            \"storage\"\n",
    "        )\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.indices.vector_store.base.VectorStoreIndex object at 0x285c53d40>\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "CITATION_QA_TEMPLATE = PromptTemplate(\n",
    "    \"Please provide an answer based solely on the provided sources. \"\n",
    "    \"When referencing information from a source, \"\n",
    "    \"cite the appropriate source(s) using their corresponding numbers. \"\n",
    "    \"Every answer should include at least one source citation. \"\n",
    "    \"Only cite a source when you are explicitly referencing it. \"\n",
    "    \"If none of the sources are helpful, you should indicate that. \"\n",
    "    \"For example:\\n\"\n",
    "    \"Source 1:\\n\"\n",
    "    \"The sky is red in the evening and blue in the morning.\\n\"\n",
    "    \"Source 2:\\n\"\n",
    "    \"Water is wet when the sky is red.\\n\"\n",
    "    \"Query: When is water wet?\\n\"\n",
    "    \"Answer: Water will be wet when the sky is red [2], \"\n",
    "    \"which occurs in the evening [1].\\n\"\n",
    "    \"Now it's your turn. Below are several numbered sources of information:\"\n",
    "    \"\\n------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "CITATION_REFINE_TEMPLATE = PromptTemplate(\n",
    "    \"Please provide an answer based solely on the provided sources. \"\n",
    "    \"When referencing information from a source, \"\n",
    "    \"cite the appropriate source(s) using their corresponding numbers. \"\n",
    "    \"Every answer should include at least one source citation. \"\n",
    "    \"Only cite a source when you are explicitly referencing it. \"\n",
    "    \"If none of the sources are helpful, you should indicate that. \"\n",
    "    \"For example:\\n\"\n",
    "    \"Source 1:\\n\"\n",
    "    \"The sky is red in the evening and blue in the morning.\\n\"\n",
    "    \"Source 2:\\n\"\n",
    "    \"Water is wet when the sky is red.\\n\"\n",
    "    \"Query: When is water wet?\\n\"\n",
    "    \"Answer: Water will be wet when the sky is red [2], \"\n",
    "    \"which occurs in the evening [1].\\n\"\n",
    "    \"Now it's your turn. \"\n",
    "    \"We have provided an existing answer: {existing_answer}\"\n",
    "    \"Below are several numbered sources of information. \"\n",
    "    \"Use them to refine the existing answer. \"\n",
    "    \"If the provided sources are not helpful, you will repeat the existing answer.\"\n",
    "    \"\\nBegin refining!\"\n",
    "    \"\\n------\\n\"\n",
    "    \"{context_msg}\"\n",
    "    \"\\n------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "DEFAULT_CITATION_CHUNK_SIZE = 512\n",
    "DEFAULT_CITATION_CHUNK_OVERLAP = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import (\n",
    "    MetadataMode,\n",
    "    NodeWithScore,\n",
    "    TextNode,\n",
    ")\n",
    "\n",
    "from llama_index.core.response_synthesizers import (\n",
    "    ResponseMode,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "\n",
    "from typing import Union, List\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "\n",
    "class CitationQueryEngineWorkflow(Workflow):\n",
    "    @step(pass_context=True)\n",
    "    async def retrieve(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> RetrieverEvent:\n",
    "        \"Entry point for RAG, triggered by a StartEvent with `query`.\"\n",
    "        query = ev.get(\"query\")\n",
    "        if not query:\n",
    "            return None\n",
    "\n",
    "        print(f\"Query the database with: {query}\")\n",
    "\n",
    "        # store the query in the global context\n",
    "        ctx.data[\"query\"] = query\n",
    "\n",
    "        if ev.index is None:\n",
    "            print(\"Index is empty, load some documents before querying!\")\n",
    "            return None\n",
    "        else:\n",
    "            print(\"Index is not empty, proceed with querying!\")\n",
    "\n",
    "        retriever = ev.index.as_retriever(similarity_top_k=2)\n",
    "        nodes = retriever.retrieve(query)\n",
    "        print(f\"Retrieved {len(nodes)} nodes.\")\n",
    "        return RetrieverEvent(nodes=nodes)\n",
    "    \n",
    "    @step(pass_context=True)\n",
    "    async def create_citation_nodes(\n",
    "        self, ctx: Context, ev: RetrieverEvent\n",
    "    ) -> CreateCitationsEvent:\n",
    "        \"\"\"\n",
    "        Modify retrieved nodes to create granular sources for citations.\n",
    "\n",
    "        Takes a list of NodeWithScore objects and splits their content\n",
    "        into smaller chunks, creating new NodeWithScore objects for each chunk.\n",
    "        Each new node is labeled as a numbered source, allowing for more precise\n",
    "        citation in query results.\n",
    "\n",
    "        Args:\n",
    "            nodes (List[NodeWithScore]): A list of NodeWithScore objects to be processed.\n",
    "\n",
    "        Returns:\n",
    "            List[NodeWithScore]: A new list of NodeWithScore objects, where each object\n",
    "            represents a smaller chunk of the original nodes, labeled as a source.\n",
    "        \"\"\"\n",
    "        nodes = ev.nodes\n",
    "\n",
    "        new_nodes: List[NodeWithScore] = []\n",
    "\n",
    "        text_splitter = SentenceSplitter(\n",
    "            chunk_size=DEFAULT_CITATION_CHUNK_SIZE,\n",
    "            chunk_overlap=DEFAULT_CITATION_CHUNK_OVERLAP,\n",
    "        )\n",
    "\n",
    "        for node in nodes:\n",
    "            text_chunks = text_splitter.split_text(\n",
    "                node.node.get_content(metadata_mode=MetadataMode.NONE)\n",
    "            )\n",
    "\n",
    "            for text_chunk in text_chunks:\n",
    "                text = f\"Source {len(new_nodes)+1}:\\n{text_chunk}\\n\"\n",
    "\n",
    "                new_node = NodeWithScore(\n",
    "                    node=TextNode.parse_obj(node.node), score=node.score\n",
    "                )\n",
    "                new_node.node.text = text\n",
    "                new_nodes.append(new_node)\n",
    "        return CreateCitationsEvent(nodes=new_nodes)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def synthesize(\n",
    "        self, ctx: Context, ev: CreateCitationsEvent\n",
    "    ) -> StopEvent:\n",
    "        \"\"\"Return a streaming response using the retrieved nodes.\"\"\"\n",
    "        llm = OpenAI(model=\"gpt-4\")\n",
    "        query = ctx.data.get(\"query\")\n",
    "        print(f\"Synthesizing response for query: {query}\")\n",
    "\n",
    "        synthesizer = get_response_synthesizer(\n",
    "            llm=llm,\n",
    "            text_qa_template=CITATION_QA_TEMPLATE,\n",
    "            refine_template=CITATION_REFINE_TEMPLATE,\n",
    "            response_mode=ResponseMode.COMPACT,\n",
    "            use_async=True,\n",
    "        )\n",
    "\n",
    "        response = await synthesizer.asynthesize(query, nodes=ev.nodes)\n",
    "        print(f\"Response: {response}\")\n",
    "        return StopEvent(result=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CitationQueryEngineWorkflow.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(CitationQueryEngineWorkflow,filename=\"CitationQueryEngineWorkflow.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = CitationQueryEngineWorkflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query the database with: What is streamlit?\n",
      "Index is not empty, proceed with querying!\n",
      "Retrieved 2 nodes.\n",
      "Synthesizing response for query: What is streamlit?\n",
      "Response: The provided sources do not contain information on what Streamlit is.\n"
     ]
    }
   ],
   "source": [
    "result = await w.run(query=\"What is streamlit?\", index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided sources do not contain information on what Streamlit is."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"{result}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 2:\n",
      "The Canada Student Grants  also saw a 40% increase in funding.[11]\n",
      "Freeland issued $15B of spending  cuts, achieved by defunding public services and cancelling\n",
      "previously announced programs.[12] A new tax 2% on stock buybacks  was also introduced.[11]Background\n",
      "Measures\n",
      "Housing6/19/24, 1:59 PM 2023 Canadian federal budget - Wikipedia\n",
      "https://en.wikipedia.org/wiki/2023_Canadian_federal_budget 1/4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.source_nodes[1].node.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever()\n",
    "retrieved_nodes = retriever.retrieve(\"What is llama_index?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NodeWithScore(node=TextNode(id_='efe653e2-8822-4209-a2d5-ac47fd7da608', embedding=None, metadata={'page_label': '2', 'file_name': '2023_canadian_budget.pdf', 'file_path': '/Users/boringtao/Projects/AutoRAG/notebooks/data/rag/2023_canadian_budget.pdf', 'file_type': 'application/pdf', 'file_size': 376126, 'creation_date': '2024-08-24', 'last_modified_date': '2024-08-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='98753a12-c109-4b52-aa66-09bc49886403', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': '2023_canadian_budget.pdf', 'file_path': '/Users/boringtao/Projects/AutoRAG/notebooks/data/rag/2023_canadian_budget.pdf', 'file_type': 'application/pdf', 'file_size': 376126, 'creation_date': '2024-08-24', 'last_modified_date': '2024-08-24'}, hash='009cebca33296a7136f7143d910b2c194cc0b12de476323a352c89b5e1e6c5ac')}, text='The budg et created the government\\'s First Home Savings Account (FHSA), offering tax savings for\\nfirst-time buyers, and budgeted roughly $925 million in 2023–2024 for the \"housing accelerator\\nfund,\" an incentive announced in Budget 2022 to encourage municipalities to make home\\nconstruction easier.[13]\\nThe budget relaxed Canada\\'s strict rules on foreign home buying, and have given more foreign stake in\\ndeveloping comme rcial real estate. They also relaxed conditions of home  buying for temporary work-\\npermit holders and international students. This is a partial reversal of the proposed two-year ban on\\nhome buying by non-Canadians for increasing housing affordability and decreasing inflation. The ban\\nwas supposed to start by January 1, 2023 and be on effect till 2025.[14]\\nConservative party  lead er Pierre Poilievre  strongly criticized the budget, arguing it included too much\\nnew spending and that such policy would result in higher inflation. The leader of the Official\\nOpposition  also stated that the housing measures announced in the budget were insufficient to solve\\nthe housing crisis.[11] Poilievre also stated that the party would not vote for the budget.\\nNDP  leader Jagmeet Singh  praised the budget as the \"biggest expansion of our health care in a\\ngeneration\", and stated NDP MPs would vote in its favour.[11]\\nOn the contrary, both Bloc Québ écois  leader Yves-François Blan chet  and Green Party leader Elizabeth\\nMay  believed the budget did not increase health care spending enough. They also expressed doubts\\nconcerning the new green investments tax credit, arguing there was no proof they would be actually\\nused to fund green projects and decried that they could be used by fossil fuel companies.[15]\\nThese fears were shared by environmental organisations such as Greenpeace Canad a, Environmental\\nDefence Canada , the Climate Action Network  and Équiterre . While they welcomes the new\\ninvestments in Renewable energy , thes e groups were distraught by the government\\'s plan to increaseReactions6/19/24, 1:59 PM 2023 Canadian federal budget - Wikipedia\\nhttps://en.wikipedia.org/wiki/2023_Canadian_federal_budget 2/4', mimetype='text/plain', start_char_idx=0, end_char_idx=2144, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.01683814288572866), NodeWithScore(node=TextNode(id_='18ddab50-efdb-4d93-9dee-44fadb71f01c', embedding=None, metadata={'page_label': '1', 'file_name': '2023_canadian_budget.pdf', 'file_path': '/Users/boringtao/Projects/AutoRAG/notebooks/data/rag/2023_canadian_budget.pdf', 'file_type': 'application/pdf', 'file_size': 376126, 'creation_date': '2024-08-24', 'last_modified_date': '2024-08-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='56c43c11-f6ca-4a54-83e3-22532567acf3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': '2023_canadian_budget.pdf', 'file_path': '/Users/boringtao/Projects/AutoRAG/notebooks/data/rag/2023_canadian_budget.pdf', 'file_type': 'application/pdf', 'file_size': 376126, 'creation_date': '2024-08-24', 'last_modified_date': '2024-08-24'}, hash='7cde4cc1bacb4d849f4806ecf9ee54638f96fe63e575fec0d796d2c68263a3df')}, text='‹\\xa02022 2024›2023 budget of the\\nCanadian federal\\ngovernment\\nSubmitted 28 March 2023\\nPresented 28 March 2023\\nParliament 44th\\nParty Liberal\\nFinance\\nministerChrystia Freeland\\nTotal revenue$456.8 billion\\n(projected)\\nTotal\\nexpenditures$496.9 billion\\n(projected)\\nDeﬁcit $40.1 billion\\n(projected)[ 1 ]\\nGDP TBA\\nWebsite 2023 Budget (http\\ns://www.budget.can\\nada.ca/2023/home-\\naccueil-en.html)\\n2023 Canadian federal budget\\nThe Cana dian federal budget for the fiscal years of 2023–24 was\\npresented to the House of Common s by Finance Minister  Chrystia\\nFreeland on 28 March 2023.[2] The budget was meant to reflect\\nPrime Minister Justin Trudeau \\'s stated policy objective to \"make\\nlife more affordable for Canadia ns\"[3] while also reducing\\ngovernment expenditures.[4]\\nThe 2023  budget is the seventh budget document introduced in\\nthe House of Commons  under the premiership of Justin Trudeau .\\nIt comes at the heel of the first anniversary of the Russian\\ninvasion of Ukraine , following which Canada sent one billion\\ndollars in military aid to Ukraine .[5]\\nUnited States  President Joe Biden \\'s Inflation Reduction Act of\\n2022  included unprecedented investmen ts in initiatives aimed at\\npromoting Green growth . Canada was expected to announce\\nsimilar investments in its 2023 budget in order to remain\\ncompetitive with its southern neighbour.[6]\\nOn 22 June 2023 , all parts of the budget received Royal assent ,\\nand became law.[7]\\nThe budget included $43B in net new spending over six years,[8]\\nincluding $20B for a new 15 per cent refundable tax credit to\\npromote investment in green technologies.[9] $13B was also\\nallocated to implement a means-tested dental care program, a\\npolicy originating in the NDP-Libera l deal of 2022.[8] The Canadian Dental Care Plan  began rollout in\\nDecember 2023.[10]\\nThe budget introduced a \"grocery rebate\" of up to $467 for eligible families and up to $234 for eligible\\nsingle people with no kids. The Canada Student Grants  also saw a 40% increase in funding.[11]\\nFreeland issued $15B of spending  cuts, achieved by defunding public services and cancelling\\npreviously announced programs.[12] A new tax 2% on stock buybacks  was also introduced.[11]Background\\nMeasures\\nHousing6/19/24, 1:59 PM 2023 Canadian federal budget - Wikipedia\\nhttps://en.wikipedia.org/wiki/2023_Canadian_federal_budget 1/4', mimetype='text/plain', start_char_idx=0, end_char_idx=2321, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.013997433070720964)]\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.data_structs import Node\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=ResponseMode.COMPACT\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(response_synthesizer=response_synthesizer)\n",
    "response = query_engine.query(\"What is streamlit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit is a popular open-source Python library that is used to create web applications for machine learning and data science projects. It allows users to easily build interactive and customizable web interfaces for their Python scripts without requiring extensive web development knowledge.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autorag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
